{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60616725-5b8b-4118-a6a2-246fa79b3bc4",
   "metadata": {},
   "source": [
    "# Sinkhorn Optimal Transport Benchmarking with PyKeOps\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Optimal transport (OT) is a powerful tool for comparing probability measures. In many applications—such as computer vision, machine learning, and graphics—it is beneficial to compute OT efficiently. The entropic regularized OT problem is given by\n",
    "\n",
    "$$\n",
    "\\min_{P \\geq 0} \\langle P, C \\rangle - \\varepsilon H(P)\n",
    "$$\n",
    "\n",
    "subject to\n",
    "\n",
    "$$\n",
    "P \\mathbf{1} = a,\\quad P^T \\mathbf{1} = b,\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ C $ is the cost matrix (often the squared Euclidean distance divided by 2),\n",
    "- $ H(P) = -\\sum_{ij} P_{ij} (\\log P_{ij} - 1) $ is the entropy,\n",
    "- $ \\varepsilon > 0 $ is the regularization parameter,\n",
    "- $ a $ and $ b $ are probability vectors.\n",
    "\n",
    "The Sinkhorn algorithm iteratively updates scaling factors \\( u \\) and \\( v \\) such that the optimal coupling is recovered as\n",
    "\n",
    "$$\n",
    "P = \\operatorname{diag}(u)\\, K\\, \\operatorname{diag}(v),\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "K = \\exp\\Big(-\\frac{C}{\\varepsilon}\\Big).\n",
    "$$\n",
    "\n",
    "The iterative updates are\n",
    "\n",
    "$$\n",
    "u \\leftarrow \\frac{1}{K (b \\odot v)},\\qquad v \\leftarrow \\frac{1}{K^T (a \\odot u)},\n",
    "$$\n",
    "\n",
    "and the dual potentials are recovered via\n",
    "\n",
    "$$\n",
    "f = \\varepsilon \\log u,\\qquad g = \\varepsilon \\log v.\n",
    "$$\n",
    "\n",
    "In this notebook we compare two implementations: one using the KeOps library (which handles large-scale point clouds) and one using vanilla PyTorch. We also benchmark their performance and visualize a computed transport plan on a 2D point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b306a4d-127c-4081-b53d-4a66338dee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] /home/nizarben/.cache/keops2.2.3/Linux_ankhhaf_5.15.0-131-generic_p3.12.2 has been cleaned.\n",
      "[KeOps] Compiling cuda jit compiler engine ... OK\n",
      "[pyKeOps] Compiling nvrtc binder for python ... OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import pykeops; pykeops.clean_pykeops();\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff51f74-eda4-4ea3-83c7-5ff947a73882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "def sinkhorn_loop_keops(a, x, b, y, eps, nits):\n",
    "    B, N, D = x.shape # Batch size , source points , features\n",
    "    _, M, _ = y.shape # Batch size , target points , features\n",
    "    # Dual variables\n",
    "    a, b = a.view(B, N, 1, 1), b.view(B,1,M,1)\n",
    "    log_u_x, log_v_y = torch.zeros_like(a), torch.zeros_like(b)\n",
    "    log_a, log_b = LazyTensor(a.log()), LazyTensor(b.log())\n",
    "    # Encoding as symbolic tensors :\n",
    "    x_i = LazyTensor(x.view(B, N, 1, D))\n",
    "    y_j = LazyTensor(y.view(B, 1, M, D))\n",
    "    # Symbolic cost matrix and Gibbs kernel :\n",
    "    C_ij = ((x_i - y_j) ** 2).sum(-1) / 2\n",
    "    # Sinkhorn iterations :\n",
    "    for _ in range(nits):\n",
    "        log_u_x = - eps * (log_b+(LazyTensor(log_v_y)-C_ij)/eps).logsumexp(axis=2).view(B,N,1,1)\n",
    "        log_v_y = - eps * (log_a+(LazyTensor(log_u_x)-C_ij)/eps).logsumexp(axis=1).view(B,1,M,1)\n",
    "\n",
    "    f_x, g_y = log_u_x, log_v_y\n",
    "    return f_x.view(B, N), g_y.view(B, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6404f42d-3086-4c20-a69e-056d556f15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_loop_pytorch(a, x, b, y, eps, nits):\n",
    "    B, N, D = x.shape\n",
    "    B, M, _ = y.shape\n",
    "\n",
    "    # Reshape weights to (B, N, 1) and (B, M, 1)\n",
    "    a = a.view(B, N, 1)\n",
    "    b = b.view(B, M, 1)\n",
    "\n",
    "    # Initialize dual variables u and v as ones\n",
    "    u = torch.ones_like(a)\n",
    "    v = torch.ones_like(b)\n",
    "    \n",
    "    # Compute cost matrix: squared Euclidean distance divided by 2.\n",
    "    # x.unsqueeze(2) has shape (B, N, 1, D) and y.unsqueeze(1) has shape (B, 1, M, D),\n",
    "    # so the broadcasted difference has shape (B, N, M, D)\n",
    "    C = 0.5 * ((x.unsqueeze(2) - y.unsqueeze(1)) ** 2).sum(dim=3)  # shape: (B, N, M)\n",
    "    \n",
    "    # Compute the Gibbs kernel K = exp(-C / eps)\n",
    "    K = torch.exp(-C / eps)  # shape: (B, N, M)\n",
    "\n",
    "    # Sinkhorn iterations: update dual variables u and v.\n",
    "    # Use torch.bmm for batch matrix multiply:\n",
    "    for _ in range(nits):\n",
    "        u = 1.0 / (torch.bmm(K, b * v) + 1e-9)  # (B, N, 1)\n",
    "        v = 1.0 / (torch.bmm(K.transpose(1, 2), a * u) + 1e-9)  # (B, M, 1)\n",
    "\n",
    "    # Compute dual potentials as f = eps*log(u) and g = eps*log(v)\n",
    "    fx = eps * torch.log(u + 1e-9)\n",
    "    gy = eps * torch.log(v + 1e-9)\n",
    "    \n",
    "    # Reshape the potentials to remove the singleton dimension.\n",
    "    return fx.view(B, N), gy.view(B, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3c04f3-8f36-44c9-9b50-52aa06dad8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Generating code for Max_SumShiftExpWeight_Reduction reduction (with parameters 0) of formula [a+(b-1/2*Sum((c-d)**2))/e,1] with a=Var(0,1,1), b=Var(1,1,1), c=Var(2,3,0), d=Var(3,3,1), e=Var(4,1,2) ... OK\n",
      "[KeOps] Generating code for Max_SumShiftExpWeight_Reduction reduction (with parameters 1) of formula [a+(b-1/2*Sum((c-d)**2))/e,1] with a=Var(0,1,0), b=Var(1,1,0), c=Var(2,3,0), d=Var(3,3,1), e=Var(4,1,2) ... OK\n",
      "Source potentials close: True\n",
      "Target potentials close: True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a small random example.\n",
    "B, N, M, D = 2, 5, 4, 3  # Batch size, number of source points, number of target points, feature dimension\n",
    "eps = 0.1\n",
    "nits = 10\n",
    "\n",
    "# Create random tensors on the chosen device.\n",
    "a = torch.rand(B, N, device=device)\n",
    "x = torch.rand(B, N, D, device=device)\n",
    "b = torch.rand(B, M, device=device)\n",
    "y = torch.rand(B, M, D, device=device)\n",
    "\n",
    "# Normalize the weight vectors so they sum to 1\n",
    "a = a / a.sum(dim=1, keepdim=True)\n",
    "b = b / b.sum(dim=1, keepdim=True)\n",
    "\n",
    "# Compute the dual potentials with both methods.\n",
    "fx_keops, gy_keops = sinkhorn_loop_keops(a, x, b, y, eps, nits)\n",
    "fx_torch, gy_torch = sinkhorn_loop_pytorch(a, x, b, y, eps, nits)\n",
    "\n",
    "# Test if the results compute the same result\n",
    "close_fx = torch.allclose(fx_keops, fx_torch, atol=1e-6)\n",
    "close_gy = torch.allclose(gy_keops, gy_torch, atol=1e-6)\n",
    "\n",
    "print(\"Source potentials close:\", close_fx)\n",
    "print(\"Target potentials close:\", close_gy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c285afdb-2f2f-441c-958a-4ab3c24253d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_function(func, a, x, b, y, eps, nits, n_iter=5, warmup=2):\n",
    "    \"\"\"\n",
    "    Benchmark a Sinkhorn function on GPU using CUDA events and memory stats.\n",
    "    \n",
    "    Parameters:\n",
    "      func   : the sinkhorn function to benchmark.\n",
    "      a, x, b, y, eps, nits : input parameters.\n",
    "      n_iter : number of timed iterations.\n",
    "      warmup : number of warmup iterations.\n",
    "      \n",
    "    Returns:\n",
    "      avg_time_ms : Average execution time per iteration in milliseconds.\n",
    "      peak_memory_MB : Peak GPU memory usage in MB.\n",
    "    \"\"\"\n",
    "    device = a.device\n",
    "    \n",
    "    # Warmup runs.\n",
    "    for _ in range(warmup):\n",
    "        _ = func(a, x, b, y, eps, nits)\n",
    "        torch.cuda.synchronize(device)\n",
    "    \n",
    "    # Reset peak memory stats.\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    \n",
    "    times = []\n",
    "    for _ in range(n_iter):\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        \n",
    "        _ = func(a, x, b, y, eps, nits)\n",
    "        \n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize(device)\n",
    "        times.append(start_event.elapsed_time(end_event))\n",
    "    \n",
    "    avg_time_ms = sum(times) / len(times)\n",
    "    peak_memory_bytes = torch.cuda.max_memory_allocated(device)\n",
    "    peak_memory_MB = peak_memory_bytes / (1024 ** 2)\n",
    "    \n",
    "    return avg_time_ms, peak_memory_MB\n",
    "\n",
    "\n",
    "def run_benchmarks(func, sizes, eps, nits, n_iter=5, warmup=2):\n",
    "    \"\"\"\n",
    "    Run benchmarks for a given Sinkhorn function over various matrix sizes.\n",
    "    \n",
    "    Parameters:\n",
    "      func  : sinkhorn function to benchmark.\n",
    "      sizes : list of tuples (B, N, M, D).\n",
    "      eps, nits, n_iter, warmup : parameters for benchmarking.\n",
    "    \n",
    "    Returns:\n",
    "      Dictionary mapping size to benchmark results or error messages.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    for (B, N, M, D) in sizes:\n",
    "        print(f\"\\nBenchmarking size: B={B}, N={N}, M={M}, D={D}\")\n",
    "        try:\n",
    "            a = torch.rand(B, N, device=device)\n",
    "            x = torch.rand(B, N, D, device=device)\n",
    "            b = torch.rand(B, M, device=device)\n",
    "            y = torch.rand(B, M, D, device=device)\n",
    "            \n",
    "            # Normalize weights.\n",
    "            a = a / a.sum(dim=1, keepdim=True)\n",
    "            b = b / b.sum(dim=1, keepdim=True)\n",
    "            \n",
    "            time_ms, mem_MB = benchmark_function(func, a, x, b, y, eps, nits, n_iter, warmup)\n",
    "            results[(B, N, M, D)] = {\"time_ms\": time_ms, \"mem_MB\": mem_MB}\n",
    "            print(f\"Avg time: {time_ms:.2f} ms, Peak memory: {mem_MB:.2f} MB\")\n",
    "        except Exception as e:\n",
    "            results[(B, N, M, D)] = {\"error\": str(e)}\n",
    "            print(\"Error encountered:\", e)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3045fecf-fbf4-4d43-9157-3c2f56048d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Benchmarking KeOps version:\n",
      "\n",
      "Benchmarking size: B=2, N=500, M=500, D=3\n",
      "Avg time: 34.88 ms, Peak memory: 8.19 MB\n",
      "\n",
      "Benchmarking size: B=4, N=2000, M=2000, D=3\n",
      "Avg time: 37.60 ms, Peak memory: 8.62 MB\n",
      "\n",
      "Benchmarking size: B=8, N=5000, M=5000, D=3\n",
      "Avg time: 50.07 ms, Peak memory: 10.57 MB\n",
      "\n",
      "Benchmarking size: B=32, N=20000, M=20000, D=3\n",
      "Avg time: 723.17 ms, Peak memory: 47.19 MB\n",
      "\n",
      "Benchmarking size: B=64, N=100000, M=100000, D=3\n",
      "Avg time: 35731.65 ms, Peak memory: 400.27 MB\n",
      "\n",
      "Benchmarking vanilla PyTorch version:\n",
      "\n",
      "Benchmarking size: B=2, N=500, M=500, D=3\n",
      "Avg time: 2.05 ms, Peak memory: 20.04 MB\n",
      "\n",
      "Benchmarking size: B=4, N=2000, M=2000, D=3\n",
      "Avg time: 7.30 ms, Peak memory: 376.44 MB\n",
      "\n",
      "Benchmarking size: B=8, N=5000, M=5000, D=3\n",
      "Avg time: 85.69 ms, Peak memory: 4587.29 MB\n",
      "\n",
      "Benchmarking size: B=32, N=20000, M=20000, D=3\n",
      "Error encountered: CUDA out of memory. Tried to allocate 143.05 GiB. GPU 0 has a total capacity of 44.34 GiB of which 43.98 GiB is free. Including non-PyTorch memory, this process has 362.00 MiB memory in use. Of the allocated memory 32.54 MiB is allocated by PyTorch, and 15.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Benchmarking size: B=64, N=100000, M=100000, D=3\n",
      "Error encountered: CUDA out of memory. Tried to allocate 7152.56 GiB. GPU 0 has a total capacity of 44.34 GiB of which 43.76 GiB is free. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 253.79 MiB is allocated by PyTorch, and 20.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Define a list of matrix sizes for benchmarking.\n",
    "matrix_sizes = [\n",
    "    (2, 500, 500, 3),      # Small\n",
    "    (4, 2000, 2000, 3),    # Medium\n",
    "    (8, 5000, 5000, 3),    # Large\n",
    "    (32, 20000, 20000, 3),\n",
    "    (64, 100000, 100000, 3)\n",
    "]\n",
    "\n",
    "print(\"Benchmarking KeOps version:\")\n",
    "bench_keops = run_benchmarks(sinkhorn_loop_keops, matrix_sizes, eps=0.1, nits=20)\n",
    "\n",
    "print(\"\\nBenchmarking vanilla PyTorch version:\")\n",
    "bench_torch = run_benchmarks(sinkhorn_loop_pytorch, matrix_sizes, eps=0.1, nits=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0d34bd-3811-4f5d-8f97-a5438d632298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transport_plan_keops(a, x, b, y, eps, nits):\n",
    "    \"\"\"\n",
    "    Reconstruct the transport plan P from KeOps-based Sinkhorn dual potentials:\n",
    "    P_{ij} = exp((f_i + g_j - C_{ij}) / eps),\n",
    "    where C_{ij} = 0.5 * ||x_i - y_j||^2.\n",
    "\n",
    "    Handles unbatched data for simplicity (B=1).\n",
    "    \"\"\"\n",
    "    # If 2D, add batch dimension\n",
    "    if x.dim() == 2:\n",
    "        x = x.unsqueeze(0)  # (1, N, D)\n",
    "        a = a.unsqueeze(0)  # (1, N)\n",
    "    if y.dim() == 2:\n",
    "        y = y.unsqueeze(0)  # (1, M, D)\n",
    "        b = b.unsqueeze(0)  # (1, M)\n",
    "\n",
    "    # Compute dual potentials\n",
    "    f_x, g_y = sinkhorn_loop_keops(a, x, b, y, eps, nits)\n",
    "\n",
    "    # Remove batch dim\n",
    "    f_x = f_x.squeeze(0)\n",
    "    g_y = g_y.squeeze(0)\n",
    "    x_2d = x.squeeze(0)\n",
    "    y_2d = y.squeeze(0)\n",
    "\n",
    "    # Explicit cost matrix\n",
    "    diff = x_2d.unsqueeze(1) - y_2d.unsqueeze(0)  # (N, M, D)\n",
    "    C = 0.5 * (diff**2).sum(dim=2)                # (N, M)\n",
    "\n",
    "    # Transport plan\n",
    "    P = torch.exp((f_x.unsqueeze(1) + g_y.unsqueeze(0) - C) / eps) * a.squeeze(0) * b\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707c2442-8aa8-40d1-8f90-101957344567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clustered_points(n_per_cluster, centers, spread=0.5):\n",
    "    \"\"\"\n",
    "    Create a set of points from multiple Gaussian clusters.\n",
    "    \n",
    "    n_per_cluster : int, number of points per cluster\n",
    "    centers       : list of cluster centers (each is a [3]-like list for 3D)\n",
    "    spread        : float, std dev for each cluster\n",
    "    Returns:\n",
    "      points (N, 3)  where N = len(centers)*n_per_cluster\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "    for c in centers:\n",
    "        c_tensor = torch.tensor(c).float()\n",
    "        cluster_points = torch.randn(n_per_cluster, 3) * spread + c_tensor\n",
    "        all_points.append(cluster_points)\n",
    "    return torch.cat(all_points, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d70e28d-7b2a-4f94-820d-2d07c542bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: two clusters\n",
    "src_centers = [\n",
    "    [-3.0, 0.0, 0.0]    # cluster 2 center\n",
    "]\n",
    "\n",
    "# Target: two clusters (shifted differently)\n",
    "tgt_centers = [\n",
    "    [3.0, 2.0, -2.0]\n",
    "]\n",
    "\n",
    "n_per_cluster = 100 \n",
    "\n",
    "x_vis = generate_clustered_points(n_per_cluster, src_centers, spread=0.8)\n",
    "y_vis = generate_clustered_points(n_per_cluster, tgt_centers, spread=0.8)\n",
    "\n",
    "# Probability weights\n",
    "N = x_vis.shape[0]\n",
    "M = y_vis.shape[0]\n",
    "a_vis = torch.rand(N); a_vis /= a_vis.sum()\n",
    "b_vis = torch.rand(M); b_vis /= b_vis.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f1f99b-a713-489b-88ad-25469f497364",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.1\n",
    "nits = 50\n",
    "P = compute_transport_plan_keops(a_vis, x_vis, b_vis, y_vis, eps, nits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba098a81-31b5-42d2-a8b5-7e9ff860e4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.5615e-10, 2.7912e-10, 1.1966e-04,  ..., 2.1178e-03, 2.9629e-08,\n",
       "         5.2128e-06],\n",
       "        [6.3751e-05, 1.4417e-03, 2.2580e-11,  ..., 3.4061e-11, 6.7719e-27,\n",
       "         1.2209e-17],\n",
       "        [3.4798e-24, 3.3761e-25, 1.2581e-12,  ..., 9.8882e-11, 4.0664e-06,\n",
       "         3.3612e-07],\n",
       "        ...,\n",
       "        [2.1434e-10, 8.1112e-11, 2.9912e-10,  ..., 2.0405e-07, 3.2708e-12,\n",
       "         2.4398e-08],\n",
       "        [4.0744e-13, 6.5334e-16, 1.4327e-14,  ..., 1.8400e-07, 2.2088e-10,\n",
       "         9.1541e-10],\n",
       "        [5.3905e-13, 1.8238e-12, 1.0676e-06,  ..., 8.7794e-07, 2.0670e-09,\n",
       "         4.2977e-06]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4d332-ddd6-4282-a325-a282e8987018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
